%\documentclass[fleqn, letter, 10pt]{article}
%\documentclass[article]{jss}
\documentclass[nojss]{jss}
%\usepackage[round,longnamesfirst]{natbib}
%\usepackage[left=1.5in,top=1.5in,right=1.5in,bottom=1.5in,nohead]{geometry} 
%\usepackage{graphicx,keyval,thumbpdf,url}
%\usepackage{hyperref}
%\usepackage{Sweave}
%\SweaveOpts{strip.white=TRUE, eps=FALSE}
%\AtBeginDocument{\setkeys{Gin}{width=0.6\textwidth}}


\usepackage[utf8]{inputenc}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath}
\usepackage{amsfonts}


%\newcommand{\strong}[1]{{\normalfont\fontseries{b}\selectfont #1}}
\newcommand{\class}[1]{\mbox{\textsf{#1}}}
\newcommand{\func}[1]{\mbox{\texttt{#1()}}}
%\newcommand{\code}[1]{\mbox{\texttt{#1}}}
%\newcommand{\pkg}[1]{\strong{#1}}
%\newcommand{\samp}[1]{`\mbox{\texttt{#1}}'}
%\newcommand{\proglang}[1]{\textsf{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\vect}[1]{\mathbf{#1}}
\newcommand{\mat}[1]{\mathbf{#1}}
%\newcommand{\sQuote}[1]{`{#1}'}
%\newcommand{\dQuote}[1]{``{#1}''}
\newcommand\R{{\mathbb{R}}}

%\DeclareMathOperator*{\argmin}{argmin}
%\DeclareMathOperator*{\argmax}{argmax}

%\setlength{\parindent}{0mm}
%\setlength{\parskip}{3mm plus2mm minus2mm}

%% \VignetteIndexEntry{MMSA: Position Sensitive P-Mer Frequency Clustering with Applications to Genomic Classification and Differentiation}


\author{Anurag Nagar\\Southern Methodist University \And
    Michael Hahsler\\Southern Methodist University}
\title{\pkg{MMSA}: Position Sensitive P-Mer Frequency Clustering with Applications to Genomic Classification and Differentiation}
%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Anurag Nagar, Michael Hahsler} %% comma-separated
\Plaintitle{MMSA: Position Sensitive P-Mer Frequency Clustering with Applications to Genomic Classification and Differentiation} %% without formatting
\Shorttitle{Position Sensitive P-Mer Frequency Clustering} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{
Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel lossy alignment techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the development of fast and inexpensive devices for microbiome-based health screening in the near future.
}
\Keywords{data mining, clustering, Markov chain}
\Plainkeywords{data mining, clustering, Markov chain} %% without formatting

%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{13}
%% \Issue{9}
%% \Month{September}
%% \Year{2004}
%% \Submitdate{2004-09-29}
%% \Acceptdate{2004-09-29}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
    Michael Hahsler\\
        Computer Science and Engineering\\
        Lyle School of Engineering\\
        Southern Methodist University\\
        P.O. Box 750122 \\
        Dallas, TX 75275-0122\\
        E-mail: \email{mhahsler@lyle.smu.edu}\\
        URL: \url{http://lyle.smu.edu/~mhahsler}
}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/1/31336-5053
%% Fax: +43/1/31336-734

%% for those who use Sweave please include the following line (with % symbols):
    %% need no \usepackage{Sweave.sty}

    %% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{document}

%\title{rEMM: Extensible Markov Model for Data Stream Clustering in R}
%\author{Michael Hahsler and Margaret H. Dunham}
%\date{}

%\maketitle
\sloppy

%\abstract{}

<<echo=FALSE>>=
options(width = 70, prompt="R> ", digits=4)
### for sampling
set.seed(1234)
@

\section{Introduction}
Recent advances in Metagenomics and the Human Microbiome provide a complex
landscape for dealing with a multitude of genomes all at once. One of the many
challenges in this field is classification of the genomes present in the
sample. Effective metagenomic classification and diversity analysis require
complex representations of taxa. In this package, we
develop a suite of tools, based on novel lossy alignment techniques that will
be applied to environmental metagenomics samples as well as human microbiome
samples. 

Markov Models in Sequence Analysis (MMSA) project used Markov Models for identification, organization, and classification of various species
based on their genetic sequences. More specifically, we use sequences for 16S rRNA gene, which is known to be conserved across species and is widely used
for identification and classification. Sequences for the 16S rRNA gene can be freely downloaded from the website of the Greengenes project ~\citep{MMSA:2012:Greengenes}.

\section{Using TRACDS for Genomic Applications}
The Extensible Markov Model (EMM) can be understood as an evolving Markov Chain (MC) model which is updated when new data is arrived. It has
several benefits over traditional Markov Models and can be used to create compact and space efficient models for data streams and other time-varying data.
The  R package rEMM \citep{MMSA:rEMM:2012}  implements a robust and stable implementation of EMM.

\section{MMSA Package}
In order to start using MMSA, the following packages must be installed: seqinr, rEMM, proxy, cluster, MASS, clusterGeneration, iGraph, caTools, bitops, DBI, RSQLite.
MMSA builds on the above packages to develop efficient storage, querying, analysis, and plotting capabilities..
\subsection{Genetic Databases}
At the heart of the MMSA package are Genetic Databases (genDB) which are used for efficient storage and retrieval. The examples below use SQLite database, but any other
compatible database such as mySQL, or mSQL can also be used. We use the sequences from Greengenes and the associated sequence ID as the primary key in the tables. 

\begin{figure}[h]
\centering
\includegraphics[width=4in]{er-diagram}
\caption{Entity Relationship diagram of genetic database}
\label{fig:ER_Diag}
\end{figure}

\section{Examples}

First, we load the library into the R environment.
<<>>=
library(MMSA)
@

The first step is to create an empty genDB into which sequences can be loaded.
<<>>=
db<-createGenDB("example.sqlite")
@
The above command creates an empty database with table structure similar to Figure \ref{fig:ER_Diag}
and stores it in the file "example.sqlite".
If a genDB already exists, then it can be opened and loaded using the \func{openGenDB} command

The next step is to load data into the database by reading FASTA files.
Since the meta info in FASTA files is not standardized, we provide several reader functions. For example,
for FASTA files for GreenGenes, we provide the function \func{addSequencesGreengenes}, which will
automatically read and parse GreenGenes FASTA files and extract the classification and sequence information. 
For each sequence, the header information will be parsed and stored in the appropriate column of the ``Classification'' table. 
For example, the kingdom value will go into the kingdom field of the table and so on. Each sequence also has a unique ID. This will
be parsed and used as the \textit{Primary Key} in the ``Classification'' and ``Sequences'' tables. Similarly, the DNA sequence will be
stored in the ``Sequences'' table as a Binary Large Object (BLOB).

The command below uses a FASTA file provided by the package, hence we use system.file instead of just a string with the file name.
<<>>= 
addSequencesGreengenes(db,
system.file("examples/phylums/Firmicutes.fasta",package="MMSA"))
@

After loading the sequences, various querying and limiting functions can be used to check the data and obtain 
a subset of the sequences.
The name of the genDB outputs the names of all the tables contained.
<<>>=
db
@
To get a count of the number of sequences in the database, the function \func{nSequences} can be used:
<<>>=
nSequences(db)
@

Similarly, the function \func{getSequences} returns the DNA sequences as a vector. The first 50 bases of the first sequence are shown as an example.
<<>>=
d<-getSequences(db)
substr(d[1],1,50)
@
The sequences can also be filtered at various ranks. For example, to get the sequences that have the genus name ``Desulfosporomusa'', the following
command is issued:
<<>>=
d<-getSequences(db,rank="genus",name="Desulfosporomusa")
@
It's very easy to obtain the various unique names stored in the database for any rank. For example, to find all names for the rank ``order'',
we use the \func{getRank}.
<<>>=
getRank(db,rank="order")
@
In the above case, the 100 sequences only contain organisms from \textit{two} different orders. 

If you would like to query more specific hierarchies, that's easily done as well. For example, if you want to find out the genuses within the phylum ``Firmicutes'',
you can use the function \func{getRank} with filters as:
<<>>=
getRank(db, rank="genus", whereRank="phylum", whereName="Firmicutes")
@
The above output shows all the genuses within the phylum ``Firmicutes''.

\subsection{Converting Sequences to NSV}
In order to create position sensitive p-mer clustering algorithms and models, we need to first create Numerical Summarization Vectors (NSVs).
The MMSA package can easily convert large number of sequences to NSV format and store them in the same database as character sequences. 
The following command will convert all the sequences to NSV format  and store them in a table called "NSV".
<<>>=
createNSVTable(db,tableName="NSV")
@
In the above function, we have accepted the default values of all the parameters such as word, overlap, and last\_window.
More parameters and filter criteria can also be easily specified as:
<<>>=
createNSVTable(db, tableName="NSV1", whereRank="genus",whereName="Thermosinus", 
window=100, overlap=0, word=3,last_window=FALSE)
@
The above command converts only those sequences that belong to the genus ``Thermosinus'' and stores them in a table called ``NSV1''.

The NSV format tables can be queried and filtered just as easily. For example, we can get the NSV sequences using the function
\func{getSequences} as before:
<<>>=
dNSV<-getSequences(db, rank="Genus", name="Desulfosporomusa",table="NSV")
@

Most of the times, we would like sequences to be in NSV format in the database as the NSVs form the basis of most operations such as model generation,
and classification. The function \func{processSequences} loads all the FASTA sequences from a direct into the database and also converts them 
into NSVs. This function saves the extra step of loading sequences and then creating NSVs explicitly. 
<<>>=
closeGenDB(db)
unlink("example.sqlite")
db<-createGenDB("example.sqlite")
processSequences(system.file("examples/phylums",package="MMSA"),db)
@

In the above code, we have first closed and deleted the existing database. This is done using the function \func{closeGenDB}. Note that the ``sequences''
table does not allow duplicate sequence IDs to be stored. The above code shows how to add \textbf{all} the FASTA files from the system directory ``phylums'' that
is a part of the MMSA package by using the \func{processSequences}. The function also automatically converts the sequences to NSV format and stores them
in a table called ``NSV''.

\subsection{Creating Models}
The NSVs created in the previous section can be used in Markov Model creation. The EMMs can be created at any level and for any set of subsequences or
the even the entire dataset of sequences. 
<<>>=
emm<- genModel(db,rank="Genus",name="Desulfosporomusa",table="NSV", limit=100, 
measure="Kullback", threshold=0.1,plus_one=TRUE)
@
The above command creates a model using a subset of the sequences in the NSV table. The "limit" parameter limits the maximum number of sequences to
be used in model creation. The returned emm model can now to saved to file or plotted using the \func{plot} function.
Often it is needed to create models at a particular rank level. For example, you may want to create individual models for all the ranks stored in the database.
For example, you might want to create models for each phylum present in the database. This can be easily accomplished using the \func{createModels}, which creates models
and stores them in a directory  with the rank's name (such as "phylum").

The above command creates models for all phylums stored in the database and stores them in a directory called "phylum"
<<>>=
createModels(modelDir=".",rank="phylum",db)
@

\subsection{Classification}
Once the models have been constructed, they can be used to score and classify new sequences. We can compare the new sequence against just one model
or all the models stored in a directory. The classification score is based on the \func{score} from the rEMM package \citep{MMSA:rEMM:2012}.

A score of how likely it is that a sequence was generated by a given EMM model can be calculated by the length-normalized 
product or sum of probabilities on the path along the new sequence.
The scores for a new sequence of length $l$ are defined as:
\begin{align}
P_\mathrm{prod} &= \sqrt[l-1]{\prod_{i=1}^{l-1}{a_{s(i)s(i+1)}}} \\
P_\mathrm{sum} &= \frac{1}{l-1} \sum_{i=1}^{l-1}{a_{s(i)s(i+1)}}
\end{align}

where $s(i)$ is the state of the $i^\textrm{th}$ data point in the new sequence it is assigned to. 
Points are assigned to the closest cluster only if the distance to the center is smaller
than the threshold. Data points which are not within the threshold of any cluster stay unassigned.
Note that for a sequence of length $l$ we have $l-1$ transitions. If we want to take the initial
transition probability also into account we extend the above equations by the additional initial probability $a_{\epsilon,s(1)}$:
\begin{align}
P_\mathrm{prod} &= \sqrt[l]{a_{\epsilon,s(1)}\,\prod_{i=1}^{l-1}{a_{s(i)s(i+1)}}} \\
P_\mathrm{sum} &= \frac{1}{l} \left( a_{\epsilon,s(1)}+\sum_{i=1}^{l-1}{a_{s(i)s(i+1)}} \right)
\end{align}

The function \func{classify} can be used to classify NSV sequences against all the models stored in a directory. It will output a data frame containing the
score matrix and the actual and predicted ranks. The following example shows how the \func{classify} works:
<<>>=
d<-getSequences(db,rank="phylum",table="NSV",limit=10,random=TRUE)
classification<-classify(modelDir=".",d)
@

Often, we would like to use a subset of the entire sequences for training and the rest for test purposes. Such a functionality is also available in the 
MMSA package. The function \func{validateModels} splits up the sequences into \textit{training} and \textit{test} datasets and used the training sequences
for generating the models. The parameter \textit{pctTest} is used to specify the fraction of sequences to be used for test dataset.
The output is a data frame containing the classification results as before.
<<>>=
validation<-validateModels(db,modelDir=".",rank="phylum",table="NSV",pctTest=0.1)
@


\subsection{Visualization}
The EMM model emm created in the previous section can be easily visualized using the MMSA package. The following command plots the EMM model "emm":
<<EMM_1, fig=TRUE, include=FALSE>>=
plot(emm$model,main=paste("Rank=",emm$rank,"Name=",emm$name))
@

\begin{figure}[h]
\centering
\includegraphics[width=.5\linewidth]{MMSA-EMM_1}
\caption{Plot of EMM}
\label{fig:EMM_Plot}
\end{figure}

\section*{Acknowledgments}
This research is supported by research grant no. R21HG005912 from the National Human Genome Research Institute (NHGRI / NIH).

%\bibliographystyle{abbrvnat}
%\bibliography{MMSA}

\bibliography{MMSA}


\end{document}
