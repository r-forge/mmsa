\name{Classification}
\alias{Classification}
\alias{createModels}
\alias{processSequences}
\alias{validateModels}
\alias{classify}
\docType{data}
\title{
Generate models and classify sequences.
}
\description{
Function to generate and save models from a given database and use them for classification of new sequences.
}
\usage{
processSequences(dir, db, reader=addSequencesGreengenes)
createModels(modelDir, rank, db, selection, limit=-1)
classify(modelDir, NSVList)
validateModels(db, modelDir, rank, table="NSV", pctTest=0.1)
}
\arguments{
	\item{db}{Handle of the database containing the sequences.}
	\item{reader}{Reader function used to interpret the FASTA meta information.}
	\item{dir}{Directory which contains the FASTA format files which are to be read in.}
	\item{modelDir}{Directory where models are stored.}
	\item{NSVList}{List of NSV sequences, which can be generated by getSequences method. They should contain rank and name attributes.}
	\item{rank}{Name of the rank (for example, phylum, class) at which the model is to be built.}
	\item{table}{Table in the database db which contains the NSV that are to be used for creating the model.}
	\item{selection}{Numeric vector indicating which sequences to be used for creating the model. By default, all sequences are used for model creation.}
	\item{limit}{Number of sequences to consider while creating a genmodel. By default, all sequences are considered and value is -1.}
	\item{pctTest}{Fraction of sequences within each rank to be used for testing.}
}
\value{
	{classify and validateModels functions return a data.frame containing the classification matrix and actual and predicted values.}
}
\seealso{
	\code{\link{getSequences}}
}
\details{
	These group of functions are used to convert sequences into models and then use these models for classification of new sequences.
	The function processSequences converts all the sequence files in a directory to NSV format in a database specified by the db parameter.
	The function createModels creates models at a given rank (for example, phylum) and stores the models in a serialized format in the directory specified by the first parameter. 
	The function classify finds similarity between a sequence (whose classification hierarchy may be unknown) and the models saved in a directory. The function goes through all the sequences in the seqFile (which should be in FASTA format) and finds their similarity with all the models in the modelDir directory. The output is a dataframe with the similarity score matrix, and also the actual and predicted ranks.
	The function validateModels reads in all the FASTA files in the dir and uses a fraction of those for generating models for each rank and stores the models in the modelDir. It uses the remaining sequences for testing and tries to classify the test sequences by comparing their similarity with the generated models. It outputs a dataframe with the similarity score matrix, and also the actual and predicted ranks.
}
\examples{
#create a db for demonstration purpose
db<-createGenDB("MMSAExample.sqlite")
processSequences(system.file("examples/phylums",package="MMSA"),db)
rank<-"phylum"
if (!file.exists("MMSAExample"))
	dir.create("MMSAExample")
#Create a "phylum" folder within the MMSAExample directory and store models there
createModels("MMSAExample",rank,db)
d<-getSequences(db,rank,table="NSV")
classification<-classify("MMSAExample",d)

#run validation on the db
validation<-validateModels(db,"MMSAExample",rank,table="NSV",pctTest=0.1)

#delete the database file to cleanup
closeGenDB(db)
unlink("MMSAExample.sqlite")
unlink("MMSAExample/",recursive=TRUE)
}
\keyword{datasets}
